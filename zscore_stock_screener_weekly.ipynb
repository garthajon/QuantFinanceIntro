{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhwT5ItMLXVgZtR6ylr3yP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garthajon/QuantFinanceIntro/blob/main/zscore_stock_screener_weekly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxhEF72Am2AQ",
        "outputId": "c1ce4429-7cce-42ba-bd12-5b70508541a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1373205944.py:16: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  sp500_table = pd.read_html(resp.text)[0]\n",
            "/tmp/ipython-input-1373205944.py:26: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(tickers, start=start_date, end=end_date, interval=\"1d\", progress=False)[\"Close\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 503 tickers (1 year daily)...\n",
            "503 tickers with complete data.\n",
            "\n",
            "\n",
            "=== STOCKS WITH Z-SCORE > 1.5 OR < -1.5 ===\n",
            "\n",
            "       Z-Score\n",
            "K     5.903311\n",
            "CTVA  3.407544\n",
            "FICO  3.304776\n",
            "AES   3.303453\n",
            "MRK   3.057376\n",
            "PFE   2.921064\n",
            "BIIB  2.704487\n",
            "TMO   2.436415\n",
            "NWS   2.313112\n",
            "ABBV  2.212478\n",
            "HUM   2.107414\n",
            "NWSA  1.989117\n",
            "DHR   1.889347\n",
            "PNW   1.706330\n",
            "EFX   1.693143\n",
            "CAG   1.667022\n",
            "BMY   1.642713\n",
            "IPG   1.621426\n",
            "A     1.592956\n",
            "WYNN  1.572016\n",
            "LVS   1.568083\n",
            "OMC   1.500891\n",
            "DOC  -1.535492\n",
            "ARE  -1.755550\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ------------------ Fetch S&P 500 tickers ------------------\n",
        "sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "headers = {\n",
        "    \"User-Agent\": (\n",
        "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0 Safari/537.36\"\n",
        "    )\n",
        "}\n",
        "resp = requests.get(sp500_url, headers=headers)\n",
        "sp500_table = pd.read_html(resp.text)[0]\n",
        "\n",
        "# Normalize tickers for yfinance (BRK.B -> BRK-B)\n",
        "tickers = [s.replace(\".\", \"-\").strip() for s in sp500_table['Symbol']]\n",
        "\n",
        "# ------------------ Fetch daily close price data ------------------\n",
        "end_date = datetime.today()\n",
        "start_date = end_date - timedelta(weeks=52*1)  # 1 year\n",
        "\n",
        "print(f\"Downloading {len(tickers)} tickers (1 year daily)...\")\n",
        "data = yf.download(tickers, start=start_date, end=end_date, interval=\"1d\", progress=False)[\"Close\"]\n",
        "\n",
        "# Drop tickers with incomplete data\n",
        "data = data.dropna(axis=1, how=\"any\")\n",
        "available_tickers = list(data.columns)\n",
        "print(f\"{len(available_tickers)} tickers with complete data.\\n\")\n",
        "\n",
        "# ------------------ Compute weekly annualized volatility ------------------\n",
        "# Resample daily returns into weekly std * sqrt(252) for annualized volatility\n",
        "returns = data.pct_change().dropna()\n",
        "weekly_std = returns.resample('W').std() * np.sqrt(252)\n",
        "\n",
        "# ------------------ Standardize to Z-score ------------------\n",
        "zscore_params = {}\n",
        "for ticker in available_tickers:\n",
        "    mu = weekly_std[ticker].mean()\n",
        "    sigma = weekly_std[ticker].std(ddof=0)\n",
        "    zscore_params[ticker] = (mu, sigma)\n",
        "\n",
        "latest_weekly_std = weekly_std.iloc[-1]\n",
        "zscores = pd.Series({t: (latest_weekly_std[t] - zscore_params[t][0]) / zscore_params[t][1]\n",
        "                     for t in available_tickers})\n",
        "\n",
        "# ------------------ Select tickers with extreme Z-scores ------------------\n",
        "extreme_z = zscores[(zscores > 1.5) | (zscores < -1.5)].sort_values(ascending=False)\n",
        "\n",
        "# ------------------ Display screener ------------------\n",
        "print(\"\\n=== STOCKS WITH Z-SCORE > 1.5 OR < -1.5 ===\\n\")\n",
        "print(extreme_z.to_frame(\"Z-Score\"))\n"
      ]
    }
  ]
}